# Data-Cleaning
This is a repository for all my Data cleaning Projects

Data cleaning is one of the fundamental process or workflow of a data project. This process is done in order to improve the overall quality of a dataset for further analysis or product building in AI. Usually, after data is collected from different sources, it tends to be what is known as "Dirty Data". In other words, raw datasets usually come with a lot of inconsistencies and missing value. According to IBM, High-quality or “clean” data is crucial for effectively adopting artificial intelligence (AI) and automation tools. Organizations can also use AI to help streamline the data cleaning process.

# Process Of Data Cleaning
Data cleaning involves sevral processes and techniques. They are
- Standardisation
- Finding outliers
- Deduplication
- Removing or filling up missing values (In a situation where there's no way to know about a value, you use what is known as Interpolation to estimate the unknown data points. This is particular in Geospatial data)
- Validation

# Tools used in Data Cleaning
- Python
- SQL
- Excel

# Project 1: UK Jobs Data Cleaning
In this project, the dataset comprises of all Data jobs and the skills required. The data was collected from multiple websites such as Indeed, glassdoor etc. Our goal is to clean this data for Exploratory Data Analysis